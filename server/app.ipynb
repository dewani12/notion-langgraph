{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a20b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, List\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from uuid import uuid4\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm=ChatGroq(model=\"llama3-8b-8192\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78c41ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "tools=[search_tool]\n",
    "\n",
    "memory=MemorySaver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec652be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools=llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87e1d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "async def model(state: AgentState):\n",
    "    result = await llm_with_tools.ainvoke(state[\"messages\"])\n",
    "    return {\n",
    "        \"messages\": [result], \n",
    "    }\n",
    "\n",
    "async def tools_router(state: AgentState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    if(hasattr(last_message, \"tool_calls\") and len(last_message.tool_calls) > 0):\n",
    "        return \"tool_node\"\n",
    "    else: \n",
    "        return END\n",
    "    \n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"model\", model)\n",
    "graph_builder.add_node(\"tool_node\", tool_node)\n",
    "graph_builder.set_entry_point(\"model\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"model\",\n",
    "    tools_router,\n",
    "    {\n",
    "        \"tool_node\": \"tool_node\",\n",
    "        END: END,\n",
    "    })\n",
    "graph_builder.add_edge(\"tool_node\", \"model\")\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6054b087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc1db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={})]}}, 'name': 'LangGraph', 'tags': [], 'run_id': '60444c4d-3127-499f-833e-c4140055fab6', 'metadata': {'thread_id': 1}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='68a7a19a-fe0c-4966-bdf1-7d24b8b25146'), HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='63670848-a4a6-4773-b6e0-cc789a4c9879'), AIMessage(content=\"I'm doing well, thank you for asking!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1893, 'total_tokens': 1904, 'completion_time': 0.017998487, 'prompt_time': 0.210736991, 'queue_time': -0.318814871, 'total_time': 0.228735478}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--4cc20405-ff28-4088-bc92-0f8453cbe53f-0', usage_metadata={'input_tokens': 1893, 'output_tokens': 11, 'total_tokens': 1904}), HumanMessage(content='Hi, my name is dewani', additional_kwargs={}, response_metadata={}, id='ff002413-1159-4d4a-be78-65ffed0cfe2d'), AIMessage(content='Nice to meet you, Dewani!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 963, 'total_tokens': 972, 'completion_time': 0.014658125, 'prompt_time': 0.108852734, 'queue_time': 0.27065765399999997, 'total_time': 0.123510859}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--4c2613a8-0a7d-47fb-ba7f-8149840b26db-0', usage_metadata={'input_tokens': 963, 'output_tokens': 9, 'total_tokens': 972}), HumanMessage(content='Do u know me', additional_kwargs={}, response_metadata={}, id='1a7455b0-59e7-4a8f-a600-49402493684d'), AIMessage(content=\"I apologize, but I don't have any information about you, Dewani. I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 985, 'total_tokens': 1027, 'completion_time': 0.076191337, 'prompt_time': 0.468486576, 'queue_time': 4.597114984, 'total_time': 0.544677913}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--ff20c708-9296-4f30-88e0-245b11b656ef-0', usage_metadata={'input_tokens': 985, 'output_tokens': 42, 'total_tokens': 1027}), HumanMessage(content='i m a full stack AI developer can u tell me about tavily search?', additional_kwargs={}, response_metadata={}, id='5bfdbe4a-4ea9-4c65-bea1-c08bae6b482e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8ag7989vj', 'function': {'arguments': '{\"query\":\"tavily search\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 1052, 'total_tokens': 1125, 'completion_time': 0.112183033, 'prompt_time': 0.314408401, 'queue_time': 0.293424157, 'total_time': 0.426591434}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--10ace22c-1e25-4c9d-8156-cf674f5c415f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'tavily search'}, 'id': '8ag7989vj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1052, 'output_tokens': 73, 'total_tokens': 1125}), ToolMessage(content='[{\"title\": \"TavilySearch - LangChain.js\", \"url\": \"https://js.langchain.com/docs/integrations/tools/tavily_search\", \"content\": \"[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\\\n\\\\n`import { TavilySearch } from \\\\\"@langchain/tavily\\\\\";const tool = new TavilySearch({  maxResults: 5,  topic: \\\\\"general\\\\\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \\\\\"basic\\\\\",  // timeRange: \\\\\"day\\\\\",  // includeDomains: [],  // excludeDomains: [],});`\", \"score\": 0.92176014}, {\"title\": \"Tavily Search - LangChain\", \"url\": \"https://python.langchain.com/docs/integrations/tools/tavily_search/\", \"content\": \"[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\\\n\\\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \\\\\"Direct link to Overview\\\\\")\\\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\\\n\\\\nInstantiation The tool accepts various parameters during instantiation:\", \"score\": 0.91306627}, {\"title\": \"Tavily\", \"url\": \"https://tavily.com/\", \"content\": \"Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\\\n\\\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\\\n\\\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\\\n\\\\nDoes Tavily Search API provide citations for its results?\\\\n\\\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.\", \"score\": 0.90330297}]', name='tavily_search_results_json', id='8a72235f-fb26-454e-acf5-fa0a61205284', tool_call_id='8ag7989vj', artifact={'query': 'tavily search', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://js.langchain.com/docs/integrations/tools/tavily_search', 'title': 'TavilySearch - LangChain.js', 'content': '[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\n\\n`import { TavilySearch } from \"@langchain/tavily\";const tool = new TavilySearch({  maxResults: 5,  topic: \"general\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \"basic\",  // timeRange: \"day\",  // includeDomains: [],  // excludeDomains: [],});`', 'score': 0.92176014, 'raw_content': None}, {'url': 'https://python.langchain.com/docs/integrations/tools/tavily_search/', 'title': 'Tavily Search - LangChain', 'content': '[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\n\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \"Direct link to Overview\")\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\n\\nInstantiation The tool accepts various parameters during instantiation:', 'score': 0.91306627, 'raw_content': None}, {'url': 'https://tavily.com/', 'title': 'Tavily', 'content': 'Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\n\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\n\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\n\\nDoes Tavily Search API provide citations for its results?\\n\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.', 'score': 0.90330297, 'raw_content': None}], 'response_time': 1.75}), AIMessage(content='Thank you for providing the results from the Tavily Search tool call.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 1843, 'total_tokens': 1859, 'completion_time': 0.025380923, 'prompt_time': 0.216475655, 'queue_time': 0.272664533, 'total_time': 0.241856578}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--092b81ed-6c6f-4b6d-88a3-5e088dfffcc2-0', usage_metadata={'input_tokens': 1843, 'output_tokens': 16, 'total_tokens': 1859}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='4b09fac8-f57e-4dad-b79c-d91553cf277a'), AIMessage(content=\"I apologize, but I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you, Dewani. I'm a new AI every time you interact with me, and I don't retain any information from previous conversations.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1873, 'total_tokens': 1929, 'completion_time': 0.087353622, 'prompt_time': 0.208279158, 'queue_time': 0.26856109000000006, 'total_time': 0.29563278}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b1f9a1e-5db7-457e-bd6f-624942bd8bfa-0', usage_metadata={'input_tokens': 1873, 'output_tokens': 56, 'total_tokens': 1929}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='571c063c-f5cb-4a2e-823d-6cfedf039a9e')]}}, 'name': 'model', 'tags': ['graph:step:20'], 'run_id': 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d', 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63'}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6']}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='68a7a19a-fe0c-4966-bdf1-7d24b8b25146'), HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='63670848-a4a6-4773-b6e0-cc789a4c9879'), AIMessage(content=\"I'm doing well, thank you for asking!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1893, 'total_tokens': 1904, 'completion_time': 0.017998487, 'prompt_time': 0.210736991, 'queue_time': -0.318814871, 'total_time': 0.228735478}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--4cc20405-ff28-4088-bc92-0f8453cbe53f-0', usage_metadata={'input_tokens': 1893, 'output_tokens': 11, 'total_tokens': 1904}), HumanMessage(content='Hi, my name is dewani', additional_kwargs={}, response_metadata={}, id='ff002413-1159-4d4a-be78-65ffed0cfe2d'), AIMessage(content='Nice to meet you, Dewani!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 963, 'total_tokens': 972, 'completion_time': 0.014658125, 'prompt_time': 0.108852734, 'queue_time': 0.27065765399999997, 'total_time': 0.123510859}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--4c2613a8-0a7d-47fb-ba7f-8149840b26db-0', usage_metadata={'input_tokens': 963, 'output_tokens': 9, 'total_tokens': 972}), HumanMessage(content='Do u know me', additional_kwargs={}, response_metadata={}, id='1a7455b0-59e7-4a8f-a600-49402493684d'), AIMessage(content=\"I apologize, but I don't have any information about you, Dewani. I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 985, 'total_tokens': 1027, 'completion_time': 0.076191337, 'prompt_time': 0.468486576, 'queue_time': 4.597114984, 'total_time': 0.544677913}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--ff20c708-9296-4f30-88e0-245b11b656ef-0', usage_metadata={'input_tokens': 985, 'output_tokens': 42, 'total_tokens': 1027}), HumanMessage(content='i m a full stack AI developer can u tell me about tavily search?', additional_kwargs={}, response_metadata={}, id='5bfdbe4a-4ea9-4c65-bea1-c08bae6b482e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8ag7989vj', 'function': {'arguments': '{\"query\":\"tavily search\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 1052, 'total_tokens': 1125, 'completion_time': 0.112183033, 'prompt_time': 0.314408401, 'queue_time': 0.293424157, 'total_time': 0.426591434}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--10ace22c-1e25-4c9d-8156-cf674f5c415f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'tavily search'}, 'id': '8ag7989vj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1052, 'output_tokens': 73, 'total_tokens': 1125}), ToolMessage(content='[{\"title\": \"TavilySearch - LangChain.js\", \"url\": \"https://js.langchain.com/docs/integrations/tools/tavily_search\", \"content\": \"[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\\\n\\\\n`import { TavilySearch } from \\\\\"@langchain/tavily\\\\\";const tool = new TavilySearch({  maxResults: 5,  topic: \\\\\"general\\\\\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \\\\\"basic\\\\\",  // timeRange: \\\\\"day\\\\\",  // includeDomains: [],  // excludeDomains: [],});`\", \"score\": 0.92176014}, {\"title\": \"Tavily Search - LangChain\", \"url\": \"https://python.langchain.com/docs/integrations/tools/tavily_search/\", \"content\": \"[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\\\n\\\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \\\\\"Direct link to Overview\\\\\")\\\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\\\n\\\\nInstantiation The tool accepts various parameters during instantiation:\", \"score\": 0.91306627}, {\"title\": \"Tavily\", \"url\": \"https://tavily.com/\", \"content\": \"Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\\\n\\\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\\\n\\\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\\\n\\\\nDoes Tavily Search API provide citations for its results?\\\\n\\\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.\", \"score\": 0.90330297}]', name='tavily_search_results_json', id='8a72235f-fb26-454e-acf5-fa0a61205284', tool_call_id='8ag7989vj', artifact={'query': 'tavily search', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://js.langchain.com/docs/integrations/tools/tavily_search', 'title': 'TavilySearch - LangChain.js', 'content': '[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\n\\n`import { TavilySearch } from \"@langchain/tavily\";const tool = new TavilySearch({  maxResults: 5,  topic: \"general\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \"basic\",  // timeRange: \"day\",  // includeDomains: [],  // excludeDomains: [],});`', 'score': 0.92176014, 'raw_content': None}, {'url': 'https://python.langchain.com/docs/integrations/tools/tavily_search/', 'title': 'Tavily Search - LangChain', 'content': '[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\n\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \"Direct link to Overview\")\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\n\\nInstantiation The tool accepts various parameters during instantiation:', 'score': 0.91306627, 'raw_content': None}, {'url': 'https://tavily.com/', 'title': 'Tavily', 'content': 'Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\n\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\n\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\n\\nDoes Tavily Search API provide citations for its results?\\n\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.', 'score': 0.90330297, 'raw_content': None}], 'response_time': 1.75}), AIMessage(content='Thank you for providing the results from the Tavily Search tool call.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 1843, 'total_tokens': 1859, 'completion_time': 0.025380923, 'prompt_time': 0.216475655, 'queue_time': 0.272664533, 'total_time': 0.241856578}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--092b81ed-6c6f-4b6d-88a3-5e088dfffcc2-0', usage_metadata={'input_tokens': 1843, 'output_tokens': 16, 'total_tokens': 1859}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='4b09fac8-f57e-4dad-b79c-d91553cf277a'), AIMessage(content=\"I apologize, but I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you, Dewani. I'm a new AI every time you interact with me, and I don't retain any information from previous conversations.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1873, 'total_tokens': 1929, 'completion_time': 0.087353622, 'prompt_time': 0.208279158, 'queue_time': 0.26856109000000006, 'total_time': 0.29563278}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b1f9a1e-5db7-457e-bd6f-624942bd8bfa-0', usage_metadata={'input_tokens': 1873, 'output_tokens': 56, 'total_tokens': 1929}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='571c063c-f5cb-4a2e-823d-6cfedf039a9e')]]}}, 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='I', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' apologize', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' but', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' I', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' don', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=\"'t\", additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' remember', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' Dew', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='ani', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' As', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' I', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' mentioned', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' earlier', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' I', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=\"'m\", additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' convers', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='ational', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' AI', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' our', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' conversation', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' just', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' started', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' I', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' don', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=\"'t\", additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' any', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' prior', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' knowledge', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' connections', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f')}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e'}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f', usage_metadata={'input_tokens': 1943, 'output_tokens': 44, 'total_tokens': 1987})}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chat_model_end', 'data': {'output': AIMessage(content=\"I apologize, but I don't remember you, Dewani. As I mentioned earlier, I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e'}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f', usage_metadata={'input_tokens': 1943, 'output_tokens': 44, 'total_tokens': 1987}), 'input': {'messages': [[HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='68a7a19a-fe0c-4966-bdf1-7d24b8b25146'), HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='63670848-a4a6-4773-b6e0-cc789a4c9879'), AIMessage(content=\"I'm doing well, thank you for asking!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1893, 'total_tokens': 1904, 'completion_time': 0.017998487, 'prompt_time': 0.210736991, 'queue_time': -0.318814871, 'total_time': 0.228735478}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--4cc20405-ff28-4088-bc92-0f8453cbe53f-0', usage_metadata={'input_tokens': 1893, 'output_tokens': 11, 'total_tokens': 1904}), HumanMessage(content='Hi, my name is dewani', additional_kwargs={}, response_metadata={}, id='ff002413-1159-4d4a-be78-65ffed0cfe2d'), AIMessage(content='Nice to meet you, Dewani!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 963, 'total_tokens': 972, 'completion_time': 0.014658125, 'prompt_time': 0.108852734, 'queue_time': 0.27065765399999997, 'total_time': 0.123510859}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--4c2613a8-0a7d-47fb-ba7f-8149840b26db-0', usage_metadata={'input_tokens': 963, 'output_tokens': 9, 'total_tokens': 972}), HumanMessage(content='Do u know me', additional_kwargs={}, response_metadata={}, id='1a7455b0-59e7-4a8f-a600-49402493684d'), AIMessage(content=\"I apologize, but I don't have any information about you, Dewani. I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 985, 'total_tokens': 1027, 'completion_time': 0.076191337, 'prompt_time': 0.468486576, 'queue_time': 4.597114984, 'total_time': 0.544677913}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--ff20c708-9296-4f30-88e0-245b11b656ef-0', usage_metadata={'input_tokens': 985, 'output_tokens': 42, 'total_tokens': 1027}), HumanMessage(content='i m a full stack AI developer can u tell me about tavily search?', additional_kwargs={}, response_metadata={}, id='5bfdbe4a-4ea9-4c65-bea1-c08bae6b482e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8ag7989vj', 'function': {'arguments': '{\"query\":\"tavily search\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 1052, 'total_tokens': 1125, 'completion_time': 0.112183033, 'prompt_time': 0.314408401, 'queue_time': 0.293424157, 'total_time': 0.426591434}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--10ace22c-1e25-4c9d-8156-cf674f5c415f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'tavily search'}, 'id': '8ag7989vj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1052, 'output_tokens': 73, 'total_tokens': 1125}), ToolMessage(content='[{\"title\": \"TavilySearch - LangChain.js\", \"url\": \"https://js.langchain.com/docs/integrations/tools/tavily_search\", \"content\": \"[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\\\n\\\\n`import { TavilySearch } from \\\\\"@langchain/tavily\\\\\";const tool = new TavilySearch({  maxResults: 5,  topic: \\\\\"general\\\\\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \\\\\"basic\\\\\",  // timeRange: \\\\\"day\\\\\",  // includeDomains: [],  // excludeDomains: [],});`\", \"score\": 0.92176014}, {\"title\": \"Tavily Search - LangChain\", \"url\": \"https://python.langchain.com/docs/integrations/tools/tavily_search/\", \"content\": \"[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\\\n\\\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \\\\\"Direct link to Overview\\\\\")\\\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\\\n\\\\nInstantiation The tool accepts various parameters during instantiation:\", \"score\": 0.91306627}, {\"title\": \"Tavily\", \"url\": \"https://tavily.com/\", \"content\": \"Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\\\n\\\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\\\n\\\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\\\n\\\\nDoes Tavily Search API provide citations for its results?\\\\n\\\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.\", \"score\": 0.90330297}]', name='tavily_search_results_json', id='8a72235f-fb26-454e-acf5-fa0a61205284', tool_call_id='8ag7989vj', artifact={'query': 'tavily search', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://js.langchain.com/docs/integrations/tools/tavily_search', 'title': 'TavilySearch - LangChain.js', 'content': '[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\n\\n`import { TavilySearch } from \"@langchain/tavily\";const tool = new TavilySearch({  maxResults: 5,  topic: \"general\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \"basic\",  // timeRange: \"day\",  // includeDomains: [],  // excludeDomains: [],});`', 'score': 0.92176014, 'raw_content': None}, {'url': 'https://python.langchain.com/docs/integrations/tools/tavily_search/', 'title': 'Tavily Search - LangChain', 'content': '[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\n\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \"Direct link to Overview\")\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\n\\nInstantiation The tool accepts various parameters during instantiation:', 'score': 0.91306627, 'raw_content': None}, {'url': 'https://tavily.com/', 'title': 'Tavily', 'content': 'Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\n\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\n\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\n\\nDoes Tavily Search API provide citations for its results?\\n\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.', 'score': 0.90330297, 'raw_content': None}], 'response_time': 1.75}), AIMessage(content='Thank you for providing the results from the Tavily Search tool call.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 1843, 'total_tokens': 1859, 'completion_time': 0.025380923, 'prompt_time': 0.216475655, 'queue_time': 0.272664533, 'total_time': 0.241856578}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--092b81ed-6c6f-4b6d-88a3-5e088dfffcc2-0', usage_metadata={'input_tokens': 1843, 'output_tokens': 16, 'total_tokens': 1859}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='4b09fac8-f57e-4dad-b79c-d91553cf277a'), AIMessage(content=\"I apologize, but I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you, Dewani. I'm a new AI every time you interact with me, and I don't retain any information from previous conversations.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1873, 'total_tokens': 1929, 'completion_time': 0.087353622, 'prompt_time': 0.208279158, 'queue_time': 0.26856109000000006, 'total_time': 0.29563278}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b1f9a1e-5db7-457e-bd6f-624942bd8bfa-0', usage_metadata={'input_tokens': 1873, 'output_tokens': 56, 'total_tokens': 1929}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='571c063c-f5cb-4a2e-823d-6cfedf039a9e')]]}}, 'run_id': 'a5670472-133d-4114-a02c-6410c3eebf4f', 'name': 'ChatGroq', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63', 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='68a7a19a-fe0c-4966-bdf1-7d24b8b25146'), HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='63670848-a4a6-4773-b6e0-cc789a4c9879'), AIMessage(content=\"I'm doing well, thank you for asking!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1893, 'total_tokens': 1904, 'completion_time': 0.017998487, 'prompt_time': 0.210736991, 'queue_time': -0.318814871, 'total_time': 0.228735478}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--4cc20405-ff28-4088-bc92-0f8453cbe53f-0', usage_metadata={'input_tokens': 1893, 'output_tokens': 11, 'total_tokens': 1904}), HumanMessage(content='Hi, my name is dewani', additional_kwargs={}, response_metadata={}, id='ff002413-1159-4d4a-be78-65ffed0cfe2d'), AIMessage(content='Nice to meet you, Dewani!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 963, 'total_tokens': 972, 'completion_time': 0.014658125, 'prompt_time': 0.108852734, 'queue_time': 0.27065765399999997, 'total_time': 0.123510859}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--4c2613a8-0a7d-47fb-ba7f-8149840b26db-0', usage_metadata={'input_tokens': 963, 'output_tokens': 9, 'total_tokens': 972}), HumanMessage(content='Do u know me', additional_kwargs={}, response_metadata={}, id='1a7455b0-59e7-4a8f-a600-49402493684d'), AIMessage(content=\"I apologize, but I don't have any information about you, Dewani. I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 985, 'total_tokens': 1027, 'completion_time': 0.076191337, 'prompt_time': 0.468486576, 'queue_time': 4.597114984, 'total_time': 0.544677913}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--ff20c708-9296-4f30-88e0-245b11b656ef-0', usage_metadata={'input_tokens': 985, 'output_tokens': 42, 'total_tokens': 1027}), HumanMessage(content='i m a full stack AI developer can u tell me about tavily search?', additional_kwargs={}, response_metadata={}, id='5bfdbe4a-4ea9-4c65-bea1-c08bae6b482e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8ag7989vj', 'function': {'arguments': '{\"query\":\"tavily search\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 1052, 'total_tokens': 1125, 'completion_time': 0.112183033, 'prompt_time': 0.314408401, 'queue_time': 0.293424157, 'total_time': 0.426591434}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--10ace22c-1e25-4c9d-8156-cf674f5c415f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'tavily search'}, 'id': '8ag7989vj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1052, 'output_tokens': 73, 'total_tokens': 1125}), ToolMessage(content='[{\"title\": \"TavilySearch - LangChain.js\", \"url\": \"https://js.langchain.com/docs/integrations/tools/tavily_search\", \"content\": \"[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\\\n\\\\n`import { TavilySearch } from \\\\\"@langchain/tavily\\\\\";const tool = new TavilySearch({  maxResults: 5,  topic: \\\\\"general\\\\\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \\\\\"basic\\\\\",  // timeRange: \\\\\"day\\\\\",  // includeDomains: [],  // excludeDomains: [],});`\", \"score\": 0.92176014}, {\"title\": \"Tavily Search - LangChain\", \"url\": \"https://python.langchain.com/docs/integrations/tools/tavily_search/\", \"content\": \"[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\\\n\\\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \\\\\"Direct link to Overview\\\\\")\\\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\\\n\\\\nInstantiation The tool accepts various parameters during instantiation:\", \"score\": 0.91306627}, {\"title\": \"Tavily\", \"url\": \"https://tavily.com/\", \"content\": \"Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\\\n\\\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\\\n\\\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\\\n\\\\nDoes Tavily Search API provide citations for its results?\\\\n\\\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.\", \"score\": 0.90330297}]', name='tavily_search_results_json', id='8a72235f-fb26-454e-acf5-fa0a61205284', tool_call_id='8ag7989vj', artifact={'query': 'tavily search', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://js.langchain.com/docs/integrations/tools/tavily_search', 'title': 'TavilySearch - LangChain.js', 'content': '[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\n\\n`import { TavilySearch } from \"@langchain/tavily\";const tool = new TavilySearch({  maxResults: 5,  topic: \"general\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \"basic\",  // timeRange: \"day\",  // includeDomains: [],  // excludeDomains: [],});`', 'score': 0.92176014, 'raw_content': None}, {'url': 'https://python.langchain.com/docs/integrations/tools/tavily_search/', 'title': 'Tavily Search - LangChain', 'content': '[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\n\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \"Direct link to Overview\")\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\n\\nInstantiation The tool accepts various parameters during instantiation:', 'score': 0.91306627, 'raw_content': None}, {'url': 'https://tavily.com/', 'title': 'Tavily', 'content': 'Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\n\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\n\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\n\\nDoes Tavily Search API provide citations for its results?\\n\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.', 'score': 0.90330297, 'raw_content': None}], 'response_time': 1.75}), AIMessage(content='Thank you for providing the results from the Tavily Search tool call.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 1843, 'total_tokens': 1859, 'completion_time': 0.025380923, 'prompt_time': 0.216475655, 'queue_time': 0.272664533, 'total_time': 0.241856578}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--092b81ed-6c6f-4b6d-88a3-5e088dfffcc2-0', usage_metadata={'input_tokens': 1843, 'output_tokens': 16, 'total_tokens': 1859}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='4b09fac8-f57e-4dad-b79c-d91553cf277a'), AIMessage(content=\"I apologize, but I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you, Dewani. I'm a new AI every time you interact with me, and I don't retain any information from previous conversations.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1873, 'total_tokens': 1929, 'completion_time': 0.087353622, 'prompt_time': 0.208279158, 'queue_time': 0.26856109000000006, 'total_time': 0.29563278}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b1f9a1e-5db7-457e-bd6f-624942bd8bfa-0', usage_metadata={'input_tokens': 1873, 'output_tokens': 56, 'total_tokens': 1929}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='571c063c-f5cb-4a2e-823d-6cfedf039a9e'), AIMessage(content=\"I apologize, but I don't remember you, Dewani. As I mentioned earlier, I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e'}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f', usage_metadata={'input_tokens': 1943, 'output_tokens': 44, 'total_tokens': 1987})]}}, 'name': 'tools_router', 'tags': ['seq:step:3'], 'run_id': '95bf3d0b-aac2-4e5d-8901-903c0dff0291', 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63'}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chain_end', 'data': {'output': '__end__', 'input': {'messages': [HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='68a7a19a-fe0c-4966-bdf1-7d24b8b25146'), HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='63670848-a4a6-4773-b6e0-cc789a4c9879'), AIMessage(content=\"I'm doing well, thank you for asking!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1893, 'total_tokens': 1904, 'completion_time': 0.017998487, 'prompt_time': 0.210736991, 'queue_time': -0.318814871, 'total_time': 0.228735478}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--4cc20405-ff28-4088-bc92-0f8453cbe53f-0', usage_metadata={'input_tokens': 1893, 'output_tokens': 11, 'total_tokens': 1904}), HumanMessage(content='Hi, my name is dewani', additional_kwargs={}, response_metadata={}, id='ff002413-1159-4d4a-be78-65ffed0cfe2d'), AIMessage(content='Nice to meet you, Dewani!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 963, 'total_tokens': 972, 'completion_time': 0.014658125, 'prompt_time': 0.108852734, 'queue_time': 0.27065765399999997, 'total_time': 0.123510859}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--4c2613a8-0a7d-47fb-ba7f-8149840b26db-0', usage_metadata={'input_tokens': 963, 'output_tokens': 9, 'total_tokens': 972}), HumanMessage(content='Do u know me', additional_kwargs={}, response_metadata={}, id='1a7455b0-59e7-4a8f-a600-49402493684d'), AIMessage(content=\"I apologize, but I don't have any information about you, Dewani. I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 985, 'total_tokens': 1027, 'completion_time': 0.076191337, 'prompt_time': 0.468486576, 'queue_time': 4.597114984, 'total_time': 0.544677913}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--ff20c708-9296-4f30-88e0-245b11b656ef-0', usage_metadata={'input_tokens': 985, 'output_tokens': 42, 'total_tokens': 1027}), HumanMessage(content='i m a full stack AI developer can u tell me about tavily search?', additional_kwargs={}, response_metadata={}, id='5bfdbe4a-4ea9-4c65-bea1-c08bae6b482e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8ag7989vj', 'function': {'arguments': '{\"query\":\"tavily search\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 1052, 'total_tokens': 1125, 'completion_time': 0.112183033, 'prompt_time': 0.314408401, 'queue_time': 0.293424157, 'total_time': 0.426591434}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--10ace22c-1e25-4c9d-8156-cf674f5c415f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'tavily search'}, 'id': '8ag7989vj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1052, 'output_tokens': 73, 'total_tokens': 1125}), ToolMessage(content='[{\"title\": \"TavilySearch - LangChain.js\", \"url\": \"https://js.langchain.com/docs/integrations/tools/tavily_search\", \"content\": \"[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\\\n\\\\n`import { TavilySearch } from \\\\\"@langchain/tavily\\\\\";const tool = new TavilySearch({  maxResults: 5,  topic: \\\\\"general\\\\\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \\\\\"basic\\\\\",  // timeRange: \\\\\"day\\\\\",  // includeDomains: [],  // excludeDomains: [],});`\", \"score\": 0.92176014}, {\"title\": \"Tavily Search - LangChain\", \"url\": \"https://python.langchain.com/docs/integrations/tools/tavily_search/\", \"content\": \"[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\\\n\\\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \\\\\"Direct link to Overview\\\\\")\\\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\\\n\\\\nInstantiation The tool accepts various parameters during instantiation:\", \"score\": 0.91306627}, {\"title\": \"Tavily\", \"url\": \"https://tavily.com/\", \"content\": \"Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\\\n\\\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\\\n\\\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\\\n\\\\nDoes Tavily Search API provide citations for its results?\\\\n\\\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.\", \"score\": 0.90330297}]', name='tavily_search_results_json', id='8a72235f-fb26-454e-acf5-fa0a61205284', tool_call_id='8ag7989vj', artifact={'query': 'tavily search', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://js.langchain.com/docs/integrations/tools/tavily_search', 'title': 'TavilySearch - LangChain.js', 'content': '[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\n\\n`import { TavilySearch } from \"@langchain/tavily\";const tool = new TavilySearch({  maxResults: 5,  topic: \"general\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \"basic\",  // timeRange: \"day\",  // includeDomains: [],  // excludeDomains: [],});`', 'score': 0.92176014, 'raw_content': None}, {'url': 'https://python.langchain.com/docs/integrations/tools/tavily_search/', 'title': 'Tavily Search - LangChain', 'content': '[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\n\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \"Direct link to Overview\")\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\n\\nInstantiation The tool accepts various parameters during instantiation:', 'score': 0.91306627, 'raw_content': None}, {'url': 'https://tavily.com/', 'title': 'Tavily', 'content': 'Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\n\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\n\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\n\\nDoes Tavily Search API provide citations for its results?\\n\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.', 'score': 0.90330297, 'raw_content': None}], 'response_time': 1.75}), AIMessage(content='Thank you for providing the results from the Tavily Search tool call.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 1843, 'total_tokens': 1859, 'completion_time': 0.025380923, 'prompt_time': 0.216475655, 'queue_time': 0.272664533, 'total_time': 0.241856578}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--092b81ed-6c6f-4b6d-88a3-5e088dfffcc2-0', usage_metadata={'input_tokens': 1843, 'output_tokens': 16, 'total_tokens': 1859}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='4b09fac8-f57e-4dad-b79c-d91553cf277a'), AIMessage(content=\"I apologize, but I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you, Dewani. I'm a new AI every time you interact with me, and I don't retain any information from previous conversations.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1873, 'total_tokens': 1929, 'completion_time': 0.087353622, 'prompt_time': 0.208279158, 'queue_time': 0.26856109000000006, 'total_time': 0.29563278}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b1f9a1e-5db7-457e-bd6f-624942bd8bfa-0', usage_metadata={'input_tokens': 1873, 'output_tokens': 56, 'total_tokens': 1929}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='571c063c-f5cb-4a2e-823d-6cfedf039a9e'), AIMessage(content=\"I apologize, but I don't remember you, Dewani. As I mentioned earlier, I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e'}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f', usage_metadata={'input_tokens': 1943, 'output_tokens': 44, 'total_tokens': 1987})]}}, 'run_id': '95bf3d0b-aac2-4e5d-8901-903c0dff0291', 'name': 'tools_router', 'tags': ['seq:step:3'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63'}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6', 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d']}\n",
      "{'event': 'on_chain_stream', 'run_id': 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d', 'name': 'model', 'tags': ['graph:step:20'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63'}, 'data': {'chunk': {'messages': [AIMessage(content=\"I apologize, but I don't remember you, Dewani. As I mentioned earlier, I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e'}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f', usage_metadata={'input_tokens': 1943, 'output_tokens': 44, 'total_tokens': 1987})]}}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6']}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [AIMessage(content=\"I apologize, but I don't remember you, Dewani. As I mentioned earlier, I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e'}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f', usage_metadata={'input_tokens': 1943, 'output_tokens': 44, 'total_tokens': 1987})]}, 'input': {'messages': [HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='68a7a19a-fe0c-4966-bdf1-7d24b8b25146'), HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='63670848-a4a6-4773-b6e0-cc789a4c9879'), AIMessage(content=\"I'm doing well, thank you for asking!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1893, 'total_tokens': 1904, 'completion_time': 0.017998487, 'prompt_time': 0.210736991, 'queue_time': -0.318814871, 'total_time': 0.228735478}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--4cc20405-ff28-4088-bc92-0f8453cbe53f-0', usage_metadata={'input_tokens': 1893, 'output_tokens': 11, 'total_tokens': 1904}), HumanMessage(content='Hi, my name is dewani', additional_kwargs={}, response_metadata={}, id='ff002413-1159-4d4a-be78-65ffed0cfe2d'), AIMessage(content='Nice to meet you, Dewani!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 963, 'total_tokens': 972, 'completion_time': 0.014658125, 'prompt_time': 0.108852734, 'queue_time': 0.27065765399999997, 'total_time': 0.123510859}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--4c2613a8-0a7d-47fb-ba7f-8149840b26db-0', usage_metadata={'input_tokens': 963, 'output_tokens': 9, 'total_tokens': 972}), HumanMessage(content='Do u know me', additional_kwargs={}, response_metadata={}, id='1a7455b0-59e7-4a8f-a600-49402493684d'), AIMessage(content=\"I apologize, but I don't have any information about you, Dewani. I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 985, 'total_tokens': 1027, 'completion_time': 0.076191337, 'prompt_time': 0.468486576, 'queue_time': 4.597114984, 'total_time': 0.544677913}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--ff20c708-9296-4f30-88e0-245b11b656ef-0', usage_metadata={'input_tokens': 985, 'output_tokens': 42, 'total_tokens': 1027}), HumanMessage(content='i m a full stack AI developer can u tell me about tavily search?', additional_kwargs={}, response_metadata={}, id='5bfdbe4a-4ea9-4c65-bea1-c08bae6b482e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8ag7989vj', 'function': {'arguments': '{\"query\":\"tavily search\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 1052, 'total_tokens': 1125, 'completion_time': 0.112183033, 'prompt_time': 0.314408401, 'queue_time': 0.293424157, 'total_time': 0.426591434}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--10ace22c-1e25-4c9d-8156-cf674f5c415f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'tavily search'}, 'id': '8ag7989vj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1052, 'output_tokens': 73, 'total_tokens': 1125}), ToolMessage(content='[{\"title\": \"TavilySearch - LangChain.js\", \"url\": \"https://js.langchain.com/docs/integrations/tools/tavily_search\", \"content\": \"[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\\\n\\\\n`import { TavilySearch } from \\\\\"@langchain/tavily\\\\\";const tool = new TavilySearch({  maxResults: 5,  topic: \\\\\"general\\\\\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \\\\\"basic\\\\\",  // timeRange: \\\\\"day\\\\\",  // includeDomains: [],  // excludeDomains: [],});`\", \"score\": 0.92176014}, {\"title\": \"Tavily Search - LangChain\", \"url\": \"https://python.langchain.com/docs/integrations/tools/tavily_search/\", \"content\": \"[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\\\n\\\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \\\\\"Direct link to Overview\\\\\")\\\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\\\n\\\\nInstantiation The tool accepts various parameters during instantiation:\", \"score\": 0.91306627}, {\"title\": \"Tavily\", \"url\": \"https://tavily.com/\", \"content\": \"Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\\\n\\\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\\\n\\\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\\\n\\\\nDoes Tavily Search API provide citations for its results?\\\\n\\\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.\", \"score\": 0.90330297}]', name='tavily_search_results_json', id='8a72235f-fb26-454e-acf5-fa0a61205284', tool_call_id='8ag7989vj', artifact={'query': 'tavily search', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://js.langchain.com/docs/integrations/tools/tavily_search', 'title': 'TavilySearch - LangChain.js', 'content': '[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\n\\n`import { TavilySearch } from \"@langchain/tavily\";const tool = new TavilySearch({  maxResults: 5,  topic: \"general\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \"basic\",  // timeRange: \"day\",  // includeDomains: [],  // excludeDomains: [],});`', 'score': 0.92176014, 'raw_content': None}, {'url': 'https://python.langchain.com/docs/integrations/tools/tavily_search/', 'title': 'Tavily Search - LangChain', 'content': '[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\n\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \"Direct link to Overview\")\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\n\\nInstantiation The tool accepts various parameters during instantiation:', 'score': 0.91306627, 'raw_content': None}, {'url': 'https://tavily.com/', 'title': 'Tavily', 'content': 'Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\n\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\n\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\n\\nDoes Tavily Search API provide citations for its results?\\n\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.', 'score': 0.90330297, 'raw_content': None}], 'response_time': 1.75}), AIMessage(content='Thank you for providing the results from the Tavily Search tool call.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 1843, 'total_tokens': 1859, 'completion_time': 0.025380923, 'prompt_time': 0.216475655, 'queue_time': 0.272664533, 'total_time': 0.241856578}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--092b81ed-6c6f-4b6d-88a3-5e088dfffcc2-0', usage_metadata={'input_tokens': 1843, 'output_tokens': 16, 'total_tokens': 1859}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='4b09fac8-f57e-4dad-b79c-d91553cf277a'), AIMessage(content=\"I apologize, but I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you, Dewani. I'm a new AI every time you interact with me, and I don't retain any information from previous conversations.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1873, 'total_tokens': 1929, 'completion_time': 0.087353622, 'prompt_time': 0.208279158, 'queue_time': 0.26856109000000006, 'total_time': 0.29563278}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b1f9a1e-5db7-457e-bd6f-624942bd8bfa-0', usage_metadata={'input_tokens': 1873, 'output_tokens': 56, 'total_tokens': 1929}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='571c063c-f5cb-4a2e-823d-6cfedf039a9e')]}}, 'run_id': 'd0cbcdc9-d324-469b-91fa-2cfc8310bf3d', 'name': 'model', 'tags': ['graph:step:20'], 'metadata': {'thread_id': 1, 'langgraph_step': 20, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:77a2bb8e-b307-af42-47f8-fb11f3f5db63'}, 'parent_ids': ['60444c4d-3127-499f-833e-c4140055fab6']}\n",
      "{'event': 'on_chain_stream', 'run_id': '60444c4d-3127-499f-833e-c4140055fab6', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': 1}, 'data': {'chunk': {'model': {'messages': [AIMessage(content=\"I apologize, but I don't remember you, Dewani. As I mentioned earlier, I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e'}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f', usage_metadata={'input_tokens': 1943, 'output_tokens': 44, 'total_tokens': 1987})]}}}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='68a7a19a-fe0c-4966-bdf1-7d24b8b25146'), HumanMessage(content='How r u doing?', additional_kwargs={}, response_metadata={}, id='63670848-a4a6-4773-b6e0-cc789a4c9879'), AIMessage(content=\"I'm doing well, thank you for asking!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1893, 'total_tokens': 1904, 'completion_time': 0.017998487, 'prompt_time': 0.210736991, 'queue_time': -0.318814871, 'total_time': 0.228735478}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--4cc20405-ff28-4088-bc92-0f8453cbe53f-0', usage_metadata={'input_tokens': 1893, 'output_tokens': 11, 'total_tokens': 1904}), HumanMessage(content='Hi, my name is dewani', additional_kwargs={}, response_metadata={}, id='ff002413-1159-4d4a-be78-65ffed0cfe2d'), AIMessage(content='Nice to meet you, Dewani!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 963, 'total_tokens': 972, 'completion_time': 0.014658125, 'prompt_time': 0.108852734, 'queue_time': 0.27065765399999997, 'total_time': 0.123510859}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--4c2613a8-0a7d-47fb-ba7f-8149840b26db-0', usage_metadata={'input_tokens': 963, 'output_tokens': 9, 'total_tokens': 972}), HumanMessage(content='Do u know me', additional_kwargs={}, response_metadata={}, id='1a7455b0-59e7-4a8f-a600-49402493684d'), AIMessage(content=\"I apologize, but I don't have any information about you, Dewani. I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 985, 'total_tokens': 1027, 'completion_time': 0.076191337, 'prompt_time': 0.468486576, 'queue_time': 4.597114984, 'total_time': 0.544677913}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--ff20c708-9296-4f30-88e0-245b11b656ef-0', usage_metadata={'input_tokens': 985, 'output_tokens': 42, 'total_tokens': 1027}), HumanMessage(content='i m a full stack AI developer can u tell me about tavily search?', additional_kwargs={}, response_metadata={}, id='5bfdbe4a-4ea9-4c65-bea1-c08bae6b482e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8ag7989vj', 'function': {'arguments': '{\"query\":\"tavily search\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 1052, 'total_tokens': 1125, 'completion_time': 0.112183033, 'prompt_time': 0.314408401, 'queue_time': 0.293424157, 'total_time': 0.426591434}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--10ace22c-1e25-4c9d-8156-cf674f5c415f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'tavily search'}, 'id': '8ag7989vj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1052, 'output_tokens': 73, 'total_tokens': 1125}), ToolMessage(content='[{\"title\": \"TavilySearch - LangChain.js\", \"url\": \"https://js.langchain.com/docs/integrations/tools/tavily_search\", \"content\": \"[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\\\n\\\\n`import { TavilySearch } from \\\\\"@langchain/tavily\\\\\";const tool = new TavilySearch({  maxResults: 5,  topic: \\\\\"general\\\\\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \\\\\"basic\\\\\",  // timeRange: \\\\\"day\\\\\",  // includeDomains: [],  // excludeDomains: [],});`\", \"score\": 0.92176014}, {\"title\": \"Tavily Search - LangChain\", \"url\": \"https://python.langchain.com/docs/integrations/tools/tavily_search/\", \"content\": \"[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\\\n\\\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \\\\\"Direct link to Overview\\\\\")\\\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\\\n\\\\nInstantiation The tool accepts various parameters during instantiation:\", \"score\": 0.91306627}, {\"title\": \"Tavily\", \"url\": \"https://tavily.com/\", \"content\": \"Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\\\n\\\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\\\n\\\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\\\n\\\\nDoes Tavily Search API provide citations for its results?\\\\n\\\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.\", \"score\": 0.90330297}]', name='tavily_search_results_json', id='8a72235f-fb26-454e-acf5-fa0a61205284', tool_call_id='8ag7989vj', artifact={'query': 'tavily search', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://js.langchain.com/docs/integrations/tools/tavily_search', 'title': 'TavilySearch - LangChain.js', 'content': '[Tavily](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers two key endpoints, one of which being Search, which provides search results tailored for LLMs and RAG. [...] You can import and instantiate an instance of the `TavilySearch` tool like this:\\n\\n`import { TavilySearch } from \"@langchain/tavily\";const tool = new TavilySearch({  maxResults: 5,  topic: \"general\",  // includeAnswer: false,  // includeRawContent: false,  // includeImages: false,  // includeImageDescriptions: false,  // searchDepth: \"basic\",  // timeRange: \"day\",  // includeDomains: [],  // excludeDomains: [],});`', 'score': 0.92176014, 'raw_content': None}, {'url': 'https://python.langchain.com/docs/integrations/tools/tavily_search/', 'title': 'Tavily Search - LangChain', 'content': '[Tavily\\'s Search API](https://tavily.com/) is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\\n\\nOverview[\\u200b](https://python.langchain.com/docs/integrations/tools/tavily_search/#overview \"Direct link to Overview\")\\n------------------------------------------------------------------------------------------------------------------- [...] Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily\\'s Search API endpoint.\\n\\nInstantiation The tool accepts various parameters during instantiation:', 'score': 0.91306627, 'raw_content': None}, {'url': 'https://tavily.com/', 'title': 'Tavily', 'content': 'Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased information, enabling AI applications to retrieve and process data efficiently. Tavily is built with AI developers in mind, simplifying the process of integrating dynamic web information into AI-driven solutions.\\n\\nHow is Tavily Search API different from other APIs? [...] Unlike Bing, Google and SerpAPI, Tavily Search API reviews multiple sources to find the most relevant content from each source, delivering concise, ready-to-use information optimized for LLM context. This focus on RAG and LLMs ensures your AI applications access only the highest-quality data. Tavily Search API is also more affordable and flexible.\\n\\nWhat are the key advantages of using Tavily Search API? [...] Yes! Tavily offers a free plan that includes limited monthly API calls. This allows you to test its capabilities and explore how it fits into your AI projects before committing to a paid subscription. No credit card is required for the free plan.\\n\\nDoes Tavily Search API provide citations for its results?\\n\\nYes, Tavily is committed to transparency. The API includes citations for all the information it retrieves, ensuring you know exactly where the data comes from.', 'score': 0.90330297, 'raw_content': None}], 'response_time': 1.75}), AIMessage(content='Thank you for providing the results from the Tavily Search tool call.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 1843, 'total_tokens': 1859, 'completion_time': 0.025380923, 'prompt_time': 0.216475655, 'queue_time': 0.272664533, 'total_time': 0.241856578}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8af39bf2ae', 'finish_reason': 'stop', 'logprobs': None}, id='run--092b81ed-6c6f-4b6d-88a3-5e088dfffcc2-0', usage_metadata={'input_tokens': 1843, 'output_tokens': 16, 'total_tokens': 1859}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='4b09fac8-f57e-4dad-b79c-d91553cf277a'), AIMessage(content=\"I apologize, but I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you, Dewani. I'm a new AI every time you interact with me, and I don't retain any information from previous conversations.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1873, 'total_tokens': 1929, 'completion_time': 0.087353622, 'prompt_time': 0.208279158, 'queue_time': 0.26856109000000006, 'total_time': 0.29563278}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b1f9a1e-5db7-457e-bd6f-624942bd8bfa-0', usage_metadata={'input_tokens': 1873, 'output_tokens': 56, 'total_tokens': 1929}), HumanMessage(content='Do u remember me!', additional_kwargs={}, response_metadata={}, id='571c063c-f5cb-4a2e-823d-6cfedf039a9e'), AIMessage(content=\"I apologize, but I don't remember you, Dewani. As I mentioned earlier, I'm a conversational AI, and our conversation just started. I don't have any prior knowledge or connections with you.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e'}, id='run--a5670472-133d-4114-a02c-6410c3eebf4f', usage_metadata={'input_tokens': 1943, 'output_tokens': 44, 'total_tokens': 1987})]}}, 'run_id': '60444c4d-3127-499f-833e-c4140055fab6', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': 1}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": 1,\n",
    "    }\n",
    "}\n",
    "\n",
    "# async_generator\n",
    "events = graph.astream_events({\n",
    "    \"messages\": [HumanMessage(content=\"Do u remember me!\")],\n",
    "    }, config=config, version=\"v2\")\n",
    "\n",
    "async for event in events:\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
